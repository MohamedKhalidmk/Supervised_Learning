{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNvI1kq+T//WnihIlg3TI2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedKhalidmk/Supervised_Learning/blob/main/Logistic_Regression_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "QDhtKIG3zkZQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rice_dataset_raw = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/Rice_Cammeo_Osmancik.csv\")\n",
        "\n",
        "print(\"Dataset Summary Statistics:\\n\" + \"-\" * 40)\n",
        "print(rice_dataset_raw.describe())\n",
        "\n",
        "# Split into features and target\n",
        "X = rice_dataset_raw.drop(columns=['Class'])\n",
        "y = rice_dataset_raw['Class']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=2\n",
        ")\n",
        "\n",
        "print(\"\\nData Shapes:\\n\" + \"-\" * 40)\n",
        "print(f\"{'X_train shape':<15}: {X_train.shape}\")\n",
        "print(f\"{'X_test shape' :<15}: {X_test.shape}\")\n",
        "print(f\"{'y_train shape':<15}: {y_train.shape}\")\n",
        "print(f\"{'y_test shape' :<15}: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nData Types:\\n\" + \"-\" * 40)\n",
        "print(\"Features:\")\n",
        "print(X.dtypes)\n",
        "print(\"\\nTarget:\")\n",
        "print(y.dtypes)\n",
        "\n",
        "# Encode labels (Cammeo/Osmancik → 0/1)\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "print(\"\\nLabel Encoding Map:\\n\" + \"-\" * 40)\n",
        "for class_name, class_id in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
        "    print(f\"{class_name:<10} → {class_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3O7o0wy4_vq",
        "outputId": "fcae2c6b-04af-4e62-a949-cb5af2f94804"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary Statistics:\n",
            "----------------------------------------\n",
            "               Area    Perimeter  Major_Axis_Length  Minor_Axis_Length  \\\n",
            "count   3810.000000  3810.000000        3810.000000        3810.000000   \n",
            "mean   12667.727559   454.239180         188.776222          86.313750   \n",
            "std     1732.367706    35.597081          17.448679           5.729817   \n",
            "min     7551.000000   359.100006         145.264465          59.532406   \n",
            "25%    11370.500000   426.144753         174.353855          82.731695   \n",
            "50%    12421.500000   448.852493         185.810059          86.434647   \n",
            "75%    13950.000000   483.683746         203.550438          90.143677   \n",
            "max    18913.000000   548.445984         239.010498         107.542450   \n",
            "\n",
            "       Eccentricity   Convex_Area       Extent  \n",
            "count   3810.000000   3810.000000  3810.000000  \n",
            "mean       0.886871  12952.496850     0.661934  \n",
            "std        0.020818   1776.972042     0.077239  \n",
            "min        0.777233   7723.000000     0.497413  \n",
            "25%        0.872402  11626.250000     0.598862  \n",
            "50%        0.889050  12706.500000     0.645361  \n",
            "75%        0.902588  14284.000000     0.726562  \n",
            "max        0.948007  19099.000000     0.861050  \n",
            "\n",
            "Data Shapes:\n",
            "----------------------------------------\n",
            "X_train shape  : (3048, 7)\n",
            "X_test shape   : (762, 7)\n",
            "y_train shape  : (3048,)\n",
            "y_test shape   : (762,)\n",
            "\n",
            "Data Types:\n",
            "----------------------------------------\n",
            "Features:\n",
            "Area                   int64\n",
            "Perimeter            float64\n",
            "Major_Axis_Length    float64\n",
            "Minor_Axis_Length    float64\n",
            "Eccentricity         float64\n",
            "Convex_Area            int64\n",
            "Extent               float64\n",
            "dtype: object\n",
            "\n",
            "Target:\n",
            "object\n",
            "\n",
            "Label Encoding Map:\n",
            "----------------------------------------\n",
            "Cammeo     → 0\n",
            "Osmancik   → 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "eWmmjHd0Es7S"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Batch_Gradient_Descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    for i in range(self.n_iters):\n",
        "      z_pred = np.dot(X, self.weights) + self.bias\n",
        "      y_pred = self.sigmoid(z_pred)\n",
        "      dw = (1/X.shape[0])*np.dot(X.T, (y_pred-y))\n",
        "      db = (1/X.shape[0])*np.sum(y_pred-y)\n",
        "      self.weights -= self.lr*dw\n",
        "      self.bias -= self.lr*db\n",
        "      self.losses.append(self.loss(y, y_pred))\n",
        "      print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    z_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(z_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "Q7RCB4KU_9O6"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mini_batch_gradient_descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000, batch_size=32):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "    self.batch_size = batch_size\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    n_samples=X.shape[0]\n",
        "    for i in range(self.n_iters):\n",
        "     indices = np.arange(n_samples)\n",
        "     np.random.shuffle(indices)\n",
        "     X = X[indices]\n",
        "     y = y[indices]\n",
        "     for j in range(0, n_samples, self.batch_size):\n",
        "       X_batch = X[j:j+self.batch_size]\n",
        "       y_batch = y[j:j+self.batch_size]\n",
        "       z_pred = np.dot(X_batch, self.weights) + self.bias\n",
        "       y_pred = self.sigmoid(z_pred)\n",
        "       dw = (1/self.batch_size)*np.dot(X_batch.T, (y_pred-y_batch))\n",
        "       db = (1/self.batch_size)*np.sum(y_pred-y_batch)\n",
        "       self.weights -= self.lr*dw\n",
        "       self.bias -= self.lr*db\n",
        "       self.losses.append(self.loss(y_batch, y_pred))\n",
        "     print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    y_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(y_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "Ul8RNxcvP0-o"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stochastic_gradient_descent:\n",
        "  def __init__(self, learning_rate=0.001, n_iters=1000):\n",
        "    self.lr = learning_rate\n",
        "    self.n_iters = n_iters\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "  def loss(self, y, y_pred):\n",
        "    return (-y*np.log(y_pred) - (1-y)*np.log(1-y_pred)).mean()\n",
        "  def fit(self, X, y):\n",
        "    self.weights =np.zeros(X.shape[1])\n",
        "    self.bias = 0\n",
        "    self.losses = []\n",
        "    n_samples=X.shape[0]\n",
        "    for i in range(self.n_iters):\n",
        "     indices = np.arange(n_samples)\n",
        "     np.random.shuffle(indices)\n",
        "     X_shuffled = X[indices]\n",
        "     y_shuffled= y[indices]\n",
        "     for j in range(n_samples):\n",
        "       X_j = X_shuffled[j].reshape(1, -1)\n",
        "       y_j = y_shuffled[j]\n",
        "       z_pred = np.dot(X_j, self.weights) + self.bias\n",
        "       y_pred = self.sigmoid(z_pred)\n",
        "       dw = np.dot(X_j.T, (y_pred-y_j))\n",
        "       db = np.sum(y_pred-y_j)\n",
        "       self.weights -= self.lr*dw\n",
        "       self.bias -= self.lr*db\n",
        "       self.losses.append(self.loss(y_j, y_pred))\n",
        "     print(f\"epoch:{i+1}/{self.n_iters}, loss:{self.losses[-1]}\")\n",
        "  def predict(self, X):\n",
        "    z_pred = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(z_pred)\n",
        "    y_pred = np.where(y_pred>0.5, 1, 0)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "nQjHqdvfyvWW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = SGDClassifier(loss='log_loss', learning_rate='constant', eta0=0.01, max_iter=1, random_state=42)\n",
        "\n",
        "print(\"Training Progress:\\n\" + \"-\" * 30)\n",
        "\n",
        "# Epoch-wise training\n",
        "for i in range(10):\n",
        "    model1.partial_fit(X_train, y_train, classes=np.unique(y_train))\n",
        "    y_pred = model1.predict(X_test)\n",
        "    loss = log_loss(y_test, y_pred)\n",
        "    print(f\"Epoch {i+1:>2}: loss = {loss:.4f}\")\n",
        "\n",
        "# Final predictions and metrics\n",
        "y_pred = model1.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nFinal Confusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nFinal Evaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' : <10}: {acc:.4f}\")\n",
        "print(f\"{'Precision': <10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   : <10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' : <10}: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BogqBhh6xqS",
        "outputId": "ae7eb2ee-eec0-4e3e-eb49-9385b39c81e5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Progress:\n",
            "------------------------------\n",
            "Epoch  1: loss = 2.8381\n",
            "Epoch  2: loss = 2.5070\n",
            "Epoch  3: loss = 2.5070\n",
            "Epoch  4: loss = 2.5070\n",
            "Epoch  5: loss = 2.5070\n",
            "Epoch  6: loss = 2.5070\n",
            "Epoch  7: loss = 2.5070\n",
            "Epoch  8: loss = 2.5070\n",
            "Epoch  9: loss = 2.5070\n",
            "Epoch 10: loss = 2.5070\n",
            "\n",
            "Final Confusion Matrix:\n",
            "------------------------------\n",
            "[[296  25]\n",
            " [ 28 413]]\n",
            "\n",
            "Final Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9304\n",
            "Precision : 0.9429\n",
            "Recall    : 0.9365\n",
            "F1 Score  : 0.9397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Batch_Gradient_Descent(learning_rate=0.01, n_iters=10)\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "\n",
        "# Evaluation Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['BGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWkrW_Qq1RQz",
        "outputId": "52725462-3fa9-4b57-8f93-c41c35ca78e8"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:0.6931471805599454\n",
            "epoch:2/10, loss:0.6858825173690675\n",
            "epoch:3/10, loss:0.6787790919882983\n",
            "epoch:4/10, loss:0.6718331982504676\n",
            "epoch:5/10, loss:0.6650411664117513\n",
            "epoch:6/10, loss:0.6583993676143554\n",
            "epoch:7/10, loss:0.651904217933616\n",
            "epoch:8/10, loss:0.6455521820202604\n",
            "epoch:9/10, loss:0.6393397763506867\n",
            "epoch:10/10, loss:0.6332635720998794\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[292  29]\n",
            " [ 42 399]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9068\n",
            "Precision : 0.9322\n",
            "Recall    : 0.9048\n",
            "F1 Score  : 0.9183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model3 = Mini_batch_gradient_descent(learning_rate=0.01, n_iters=10, batch_size=2)\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model3.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "\n",
        "# Evaluation Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['MBGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHImTQf21rZ5",
        "outputId": "4c7833e9-0238-4d7d-a317-798c02953927"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:0.21557233375210538\n",
            "epoch:2/10, loss:0.04940319479721092\n",
            "epoch:3/10, loss:0.001240656657218024\n",
            "epoch:4/10, loss:1.2735230613861122\n",
            "epoch:5/10, loss:0.03894144054308221\n",
            "epoch:6/10, loss:0.0014969339504781719\n",
            "epoch:7/10, loss:0.026516330723311096\n",
            "epoch:8/10, loss:0.028852280197796336\n",
            "epoch:9/10, loss:0.20777594299076096\n",
            "epoch:10/10, loss:0.002554120481593923\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[296  25]\n",
            " [ 28 413]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9304\n",
            "Precision : 0.9429\n",
            "Recall    : 0.9365\n",
            "F1 Score  : 0.9397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model4 = Stochastic_gradient_descent(learning_rate=0.01, n_iters=10)\n",
        "model4.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model4.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\" + \"-\" * 30)\n",
        "print(cm)\n",
        "\n",
        "# Evaluation Metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\\n\" + \"-\" * 30)\n",
        "print(f\"{'Accuracy' :<10}: {acc:.4f}\")\n",
        "print(f\"{'Precision':<10}: {prec:.4f}\")\n",
        "print(f\"{'Recall'   :<10}: {rec:.4f}\")\n",
        "print(f\"{'F1 Score' :<10}: {f1:.4f}\")\n",
        "results['SGD'] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWIMAGL66x-s",
        "outputId": "f87b01d0-d35d-461c-8717-d626f78eba05"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1/10, loss:0.5236523275490248\n",
            "epoch:2/10, loss:0.0010527369674178427\n",
            "epoch:3/10, loss:0.08749333241809706\n",
            "epoch:4/10, loss:0.3324791757638775\n",
            "epoch:5/10, loss:0.003908255259712406\n",
            "epoch:6/10, loss:0.00161815174552399\n",
            "epoch:7/10, loss:0.08409233048960528\n",
            "epoch:8/10, loss:0.19169220907806364\n",
            "epoch:9/10, loss:0.000299622170702654\n",
            "epoch:10/10, loss:0.2350090399321735\n",
            "\n",
            "Confusion Matrix:\n",
            "------------------------------\n",
            "[[296  25]\n",
            " [ 28 413]]\n",
            "\n",
            "Evaluation Metrics:\n",
            "------------------------------\n",
            "Accuracy  : 0.9304\n",
            "Precision : 0.9429\n",
            "Recall    : 0.9365\n",
            "F1 Score  : 0.9397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Comparison (Accuracy):\")\n",
        "print(\"-\" * 40)\n",
        "for model_name, accuracy in results.items():\n",
        "    print(f\"{model_name:<10}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "Nkv8lBcM8EGV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a07ca5a-092a-4b4a-fdc8-d909fe58942f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Comparison (Accuracy):\n",
            "----------------------------------------\n",
            "BGD       : 0.9068\n",
            "MBGD      : 0.9304\n",
            "SGD       : 0.9304\n"
          ]
        }
      ]
    }
  ]
}