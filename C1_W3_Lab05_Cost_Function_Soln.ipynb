{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedKhalidmk/Supervised_Learning/blob/main/C1_W3_Lab05_Cost_Function_Soln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv5MVub009Pp"
      },
      "source": [
        "# Optional Lab: Cost Function for Logistic Regression\n",
        "\n",
        "## Goals\n",
        "In this lab, you will:\n",
        "- examine the implementation and utilize the cost function for logistic regression."
      ],
      "id": "kv5MVub009Pp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW69cP4E09Pt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "from lab_utils_common import  plot_data, sigmoid, dlc\n",
        "plt.style.use('./deeplearning.mplstyle')"
      ],
      "id": "UW69cP4E09Pt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBJ9Q_d709Pu"
      },
      "source": [
        "## Dataset\n",
        "Let's start with the same dataset as was used in the decision boundary lab."
      ],
      "id": "wBJ9Q_d709Pu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "96tvix3k09Pv"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])  #(m,n)\n",
        "y_train = np.array([0, 0, 0, 1, 1, 1])                                           #(m,)"
      ],
      "id": "96tvix3k09Pv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4VdzbUg09Pv"
      },
      "source": [
        "We will use a helper function to plot this data. The data points with label $y=1$ are shown as red crosses, while the data points with label $y=0$ are shown as blue circles."
      ],
      "id": "V4VdzbUg09Pv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE2Z0ZQu09Pv",
        "outputId": "340997c9-6981-41c6-a966-e047f4eec20f",
        "colab": {
          "referenced_widgets": [
            "004bd7dd5250410b908ba9c380d666fc"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004bd7dd5250410b908ba9c380d666fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous ‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
        "plot_data(X_train, y_train, ax)\n",
        "\n",
        "# Set both axes to be from 0-4\n",
        "ax.axis([0, 4, 0, 3.5])\n",
        "ax.set_ylabel('$x_1$', fontsize=12)\n",
        "ax.set_xlabel('$x_0$', fontsize=12)\n",
        "plt.show()"
      ],
      "id": "dE2Z0ZQu09Pv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyrsqln809Pw"
      },
      "source": [
        "## Cost function\n",
        "\n",
        "In a previous lab, you developed the *logistic loss* function. Recall, loss is defined to apply to one example. Here you combine the losses to form the **cost**, which includes all the examples.\n",
        "\n",
        "\n",
        "Recall that for logistic regression, the cost function is of the form\n",
        "\n",
        "$$ J(\\mathbf{w},b) = \\frac{1}{m} \\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
        "\n",
        "where\n",
        "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is:\n",
        "\n",
        "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
        "    \n",
        "*  where m is the number of training examples in the data set and:\n",
        "$$\n",
        "\\begin{align}\n",
        "  f_{\\mathbf{w},b}(\\mathbf{x^{(i)}}) &= g(z^{(i)})\\tag{3} \\\\\n",
        "  z^{(i)} &= \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+ b\\tag{4} \\\\\n",
        "  g(z^{(i)}) &= \\frac{1}{1+e^{-z^{(i)}}}\\tag{5}\n",
        "\\end{align}\n",
        "$$\n",
        ""
      ],
      "id": "Tyrsqln809Pw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LvQl1mt09Pw"
      },
      "source": [
        "<a name='ex-02'></a>\n",
        "#### Code Description\n",
        "\n",
        "The algorithm for `compute_cost_logistic` loops over all the examples calculating the loss for each example and accumulating the total.\n",
        "\n",
        "Note that the variables X and y are not scalar values but matrices of shape ($m, n$) and ($ùëö$,) respectively, where  $ùëõ$ is the number of features and $ùëö$ is the number of training examples.\n"
      ],
      "id": "5LvQl1mt09Pw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpsv9r4x09Px"
      },
      "outputs": [],
      "source": [
        "def compute_cost_logistic(X, y, w, b):\n",
        "    \"\"\"\n",
        "    Computes cost\n",
        "\n",
        "    Args:\n",
        "      X (ndarray (m,n)): Data, m examples with n features\n",
        "      y (ndarray (m,)) : target values\n",
        "      w (ndarray (n,)) : model parameters\n",
        "      b (scalar)       : model parameter\n",
        "\n",
        "    Returns:\n",
        "      cost (scalar): cost\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]\n",
        "\n",
        "    z_i = np.dot(X,w) + b\n",
        "    f_wb_i = sigmoid(z_i)\n",
        "    cost = (-y@np.log(f_wb_i) - (1-y)@np.log(1-f_wb_i))/m\n",
        "    print(cost)\n",
        "    return cost\n"
      ],
      "id": "Tpsv9r4x09Px"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IniWijz009Px"
      },
      "source": [
        "Check the implementation of the cost function using the cell below."
      ],
      "id": "IniWijz009Px"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjHfRPdR09Px",
        "outputId": "07f63fee-6e9f-45b9-d60b-65ff45fccee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.36686678640551745\n",
            "0.36686678640551745\n"
          ]
        }
      ],
      "source": [
        "w_tmp = np.array([1,1])\n",
        "b_tmp = -3\n",
        "print(compute_cost_logistic(X_train, y_train, w_tmp, b_tmp))"
      ],
      "id": "EjHfRPdR09Px"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTfwyUWD09Py"
      },
      "source": [
        "**Expected output**: 0.3668667864055175"
      ],
      "id": "nTfwyUWD09Py"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP8rWfrw09Py"
      },
      "source": [
        "## Example\n",
        "Now, let's see what the cost function output is for a different value of $w$.\n",
        "\n",
        "* In a previous lab, you plotted the decision boundary for  $b = -3, w_0 = 1, w_1 = 1$. That is, you had `b = -3, w = np.array([1,1])`.\n",
        "\n",
        "* Let's say you want to see if $b = -4, w_0 = 1, w_1 = 1$, or `b = -4, w = np.array([1,1])` provides a better model.\n",
        "\n",
        "Let's first plot the decision boundary for these two different $b$ values to see which one fits the data better.\n",
        "\n",
        "* For $b = -3, w_0 = 1, w_1 = 1$, we'll plot $-3 + x_0+x_1 = 0$ (shown in blue)\n",
        "* For $b = -4, w_0 = 1, w_1 = 1$, we'll plot $-4 + x_0+x_1 = 0$ (shown in magenta)"
      ],
      "id": "iP8rWfrw09Py"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJf29W-S09Py",
        "outputId": "023cd2db-c73b-470f-f5aa-a34fe530fd43",
        "colab": {
          "referenced_widgets": [
            "4c87eb64c8834d4992f415a0e627422e"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c87eb64c8834d4992f415a0e627422e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous ‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Choose values between 0 and 6\n",
        "x0 = np.arange(0,6)\n",
        "\n",
        "# Plot the two decision boundaries\n",
        "x1 = 3 - x0\n",
        "x1_other = 4 - x0\n",
        "\n",
        "fig,ax = plt.subplots(1, 1, figsize=(4,4))\n",
        "# Plot the decision boundary\n",
        "ax.plot(x0,x1, c=dlc[\"dlblue\"], label=\"$b$=-3\")\n",
        "ax.plot(x0,x1_other, c=dlc[\"dlmagenta\"], label=\"$b$=-4\")\n",
        "ax.axis([0, 4, 0, 4])\n",
        "\n",
        "# Plot the original data\n",
        "plot_data(X_train,y_train,ax)\n",
        "ax.axis([0, 4, 0, 4])\n",
        "ax.set_ylabel('$x_1$', fontsize=12)\n",
        "ax.set_xlabel('$x_0$', fontsize=12)\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title(\"Decision Boundary\")\n",
        "plt.show()"
      ],
      "id": "AJf29W-S09Py"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh4WBtRu09Pz"
      },
      "source": [
        "You can see from this plot that `b = -4, w = np.array([1,1])` is a worse model for the training data. Let's see if the cost function implementation reflects this."
      ],
      "id": "wh4WBtRu09Pz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq2mrN1T09Pz",
        "outputId": "ad07bef9-1a60-41bb-bbc5-0e3d2eb45742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.36686678640551745\n",
            "Cost for b = -3 :  0.36686678640551745\n",
            "0.5036808636748461\n",
            "Cost for b = -4 :  0.5036808636748461\n"
          ]
        }
      ],
      "source": [
        "w_array1 = np.array([1,1])\n",
        "b_1 = -3\n",
        "w_array2 = np.array([1,1])\n",
        "b_2 = -4\n",
        "\n",
        "print(\"Cost for b = -3 : \", compute_cost_logistic(X_train, y_train, w_array1, b_1))\n",
        "print(\"Cost for b = -4 : \", compute_cost_logistic(X_train, y_train, w_array2, b_2))"
      ],
      "id": "pq2mrN1T09Pz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQBa03xr09Pz"
      },
      "source": [
        "**Expected output**\n",
        "\n",
        "Cost for b = -3 :  0.3668667864055175\n",
        "\n",
        "Cost for b = -4 :  0.5036808636748461\n",
        "\n",
        "\n",
        "You can see the cost function behaves as expected and the cost for `b = -4, w = np.array([1,1])` is indeed higher than the cost for `b = -3, w = np.array([1,1])`"
      ],
      "id": "RQBa03xr09Pz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC3Ctw8i09Pz"
      },
      "source": [
        "## Congratulations!\n",
        "In this lab you examined and utilized the cost function for logistic regression."
      ],
      "id": "yC3Ctw8i09Pz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALEeMoDG09Pz"
      },
      "outputs": [],
      "source": [],
      "id": "ALEeMoDG09Pz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRS_mIyv09P0"
      },
      "outputs": [],
      "source": [],
      "id": "MRS_mIyv09P0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}